{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Course 1 - Part 4 - Lesson 4 - Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamesMcGuigan/dlaicourse/blob/master/Course%201%20-%20Part%204%20-%20Lesson%204%20-%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9-BCmi15L93",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a523f7a2-f9b7-4df1-eeeb-abe5f0074f9e"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    print(logs)\n",
        "    if(logs.get('acc')>0.99):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy', tf.losses.get_regularization_loss]\n",
        "              )\n",
        "\n",
        "model.fit(x_train, y_train, epochs=1000, callbacks=[callbacks])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.4747 - acc: 0.8310 - get_regularization_loss: 0.0000e+00{'loss': 0.47442292854785917, 'acc': 0.83106667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.4744 - acc: 0.8311 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.3594 - acc: 0.8683 - get_regularization_loss: 0.0000e+00{'loss': 0.35932894374132157, 'acc': 0.86836666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.3593 - acc: 0.8684 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.3208 - acc: 0.8812 - get_regularization_loss: 0.0000e+00{'loss': 0.3208679110904535, 'acc': 0.88116664, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.3209 - acc: 0.8812 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.8889 - get_regularization_loss: 0.0000e+00{'loss': 0.2986215451836586, 'acc': 0.8889833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 129us/sample - loss: 0.2986 - acc: 0.8890 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.8949 - get_regularization_loss: 0.0000e+00{'loss': 0.28143408829073113, 'acc': 0.89486665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.2814 - acc: 0.8949 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9006 - get_regularization_loss: 0.0000e+00{'loss': 0.2652130434850852, 'acc': 0.90063334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.2652 - acc: 0.9006 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9046 - get_regularization_loss: 0.0000e+00{'loss': 0.25198268327017626, 'acc': 0.90455, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 143us/sample - loss: 0.2520 - acc: 0.9046 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9107 - get_regularization_loss: 0.0000e+00{'loss': 0.2397626731534799, 'acc': 0.9107, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2398 - acc: 0.9107 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9131 - get_regularization_loss: 0.0000e+00{'loss': 0.22978210212687653, 'acc': 0.9131167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.2298 - acc: 0.9131 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2222 - acc: 0.9157 - get_regularization_loss: 0.0000e+00{'loss': 0.22219004747072857, 'acc': 0.9156833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.2222 - acc: 0.9157 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9211 - get_regularization_loss: 0.0000e+00{'loss': 0.2137466441700856, 'acc': 0.92105, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.2137 - acc: 0.9211 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9232 - get_regularization_loss: 0.0000e+00{'loss': 0.20615629313687484, 'acc': 0.92321664, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.2062 - acc: 0.9232 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9254 - get_regularization_loss: 0.0000e+00{'loss': 0.19759291946589946, 'acc': 0.92545, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.1976 - acc: 0.9255 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9272 - get_regularization_loss: 0.0000e+00{'loss': 0.19358770321011542, 'acc': 0.9271333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1936 - acc: 0.9271 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9294 - get_regularization_loss: 0.0000e+00{'loss': 0.18634990619719027, 'acc': 0.9294, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 149us/sample - loss: 0.1863 - acc: 0.9294 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9317 - get_regularization_loss: 0.0000e+00{'loss': 0.17794747349023818, 'acc': 0.93155, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1779 - acc: 0.9316 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9347 - get_regularization_loss: 0.0000e+00{'loss': 0.17466701212525368, 'acc': 0.93465, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1747 - acc: 0.9347 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9361 - get_regularization_loss: 0.0000e+00{'loss': 0.1696112453525265, 'acc': 0.93605, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.1696 - acc: 0.9360 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.1637 - acc: 0.9376 - get_regularization_loss: 0.0000e+00{'loss': 0.1636320685863495, 'acc': 0.93755, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.1636 - acc: 0.9376 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9392 - get_regularization_loss: 0.0000e+00{'loss': 0.15904215450584888, 'acc': 0.9393333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.1590 - acc: 0.9393 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9425 - get_regularization_loss: 0.0000e+00{'loss': 0.1519817813669642, 'acc': 0.9424833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 141us/sample - loss: 0.1520 - acc: 0.9425 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9441 - get_regularization_loss: 0.0000e+00{'loss': 0.148865971207122, 'acc': 0.94395, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 146us/sample - loss: 0.1489 - acc: 0.9439 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9447 - get_regularization_loss: 0.0000e+00{'loss': 0.14542754981753728, 'acc': 0.94478333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 9s 144us/sample - loss: 0.1454 - acc: 0.9448 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.1423 - acc: 0.9468 - get_regularization_loss: 0.0000e+00{'loss': 0.14225645619680485, 'acc': 0.9468167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1423 - acc: 0.9468 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9480 - get_regularization_loss: 0.0000e+00{'loss': 0.13956126312563816, 'acc': 0.9479833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.1396 - acc: 0.9480 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9498 - get_regularization_loss: 0.0000e+00{'loss': 0.13328161487753193, 'acc': 0.9497333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.1333 - acc: 0.9497 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9513 - get_regularization_loss: 0.0000e+00{'loss': 0.13054798361733555, 'acc': 0.9513, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1305 - acc: 0.9513 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9514 - get_regularization_loss: 0.0000e+00{'loss': 0.1273198414221406, 'acc': 0.95143336, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1273 - acc: 0.9514 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9530 - get_regularization_loss: 0.0000e+00{'loss': 0.12279017436901728, 'acc': 0.95301664, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1228 - acc: 0.9530 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9540 - get_regularization_loss: 0.0000e+00{'loss': 0.12226309026051313, 'acc': 0.9540167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1223 - acc: 0.9540 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9552 - get_regularization_loss: 0.0000e+00{'loss': 0.1193048275505503, 'acc': 0.9551333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.1193 - acc: 0.9551 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9571 - get_regularization_loss: 0.0000e+00{'loss': 0.11384940307910243, 'acc': 0.95706666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1138 - acc: 0.9571 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9569 - get_regularization_loss: 0.0000e+00{'loss': 0.11312628963962197, 'acc': 0.9568667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.1131 - acc: 0.9569 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9572 - get_regularization_loss: 0.0000e+00{'loss': 0.11396622505995134, 'acc': 0.95725, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.1140 - acc: 0.9572 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9600 - get_regularization_loss: 0.0000e+00{'loss': 0.10651608194659154, 'acc': 0.95998335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.1065 - acc: 0.9600 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9592 - get_regularization_loss: 0.0000e+00{'loss': 0.10750282568130642, 'acc': 0.95921665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.1075 - acc: 0.9592 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9615 - get_regularization_loss: 0.0000e+00{'loss': 0.10170125409141183, 'acc': 0.9615167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.1017 - acc: 0.9615 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9621 - get_regularization_loss: 0.0000e+00{'loss': 0.10385354542153266, 'acc': 0.96216667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.1039 - acc: 0.9622 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 39/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9626 - get_regularization_loss: 0.0000e+00{'loss': 0.09919209807536875, 'acc': 0.9626667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0992 - acc: 0.9627 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9628 - get_regularization_loss: 0.0000e+00{'loss': 0.09886051811122645, 'acc': 0.96285, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0989 - acc: 0.9628 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9640 - get_regularization_loss: 0.0000e+00{'loss': 0.09679932347387075, 'acc': 0.96398336, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0968 - acc: 0.9640 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9650 - get_regularization_loss: 0.0000e+00{'loss': 0.0938610854934901, 'acc': 0.96498334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0939 - acc: 0.9650 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9655 - get_regularization_loss: 0.0000e+00{'loss': 0.09151030289341386, 'acc': 0.9654833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0915 - acc: 0.9655 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "59552/60000 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9661 - get_regularization_loss: 0.0000e+00{'loss': 0.09118397662406787, 'acc': 0.96608335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0912 - acc: 0.9661 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9666 - get_regularization_loss: 0.0000e+00{'loss': 0.08822335475375875, 'acc': 0.9665667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0882 - acc: 0.9666 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9678 - get_regularization_loss: 0.0000e+00{'loss': 0.086813630373807, 'acc': 0.96781665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0868 - acc: 0.9678 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9679 - get_regularization_loss: 0.0000e+00{'loss': 0.08648864364701633, 'acc': 0.96781665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0865 - acc: 0.9678 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9689 - get_regularization_loss: 0.0000e+00{'loss': 0.08314562958541792, 'acc': 0.9687833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0831 - acc: 0.9688 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9688 - get_regularization_loss: 0.0000e+00{'loss': 0.08275762024091868, 'acc': 0.9687667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0828 - acc: 0.9688 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9689 - get_regularization_loss: 0.0000e+00{'loss': 0.08235169977713376, 'acc': 0.96895, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0824 - acc: 0.9689 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9708 - get_regularization_loss: 0.0000e+00{'loss': 0.07704284922302079, 'acc': 0.9708167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0770 - acc: 0.9708 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9703 - get_regularization_loss: 0.0000e+00{'loss': 0.07958617236359666, 'acc': 0.9702333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0796 - acc: 0.9702 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9722 - get_regularization_loss: 0.0000e+00{'loss': 0.07580488813711951, 'acc': 0.97216666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0758 - acc: 0.9722 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - get_regularization_loss: 0.0000e+00{'loss': 0.07828765084383388, 'acc': 0.97045, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0783 - acc: 0.9704 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9715 - get_regularization_loss: 0.0000e+00{'loss': 0.07554373610465166, 'acc': 0.97153336, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0755 - acc: 0.9715 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9727 - get_regularization_loss: 0.0000e+00{'loss': 0.0719696497515717, 'acc': 0.97275, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0720 - acc: 0.9728 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9725 - get_regularization_loss: 0.0000e+00{'loss': 0.07383009994387006, 'acc': 0.97253335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0738 - acc: 0.9725 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9747 - get_regularization_loss: 0.0000e+00{'loss': 0.06748322059311904, 'acc': 0.97473335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0675 - acc: 0.9747 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9733 - get_regularization_loss: 0.0000e+00{'loss': 0.07233853788793397, 'acc': 0.9733667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0723 - acc: 0.9734 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9750 - get_regularization_loss: 0.0000e+00{'loss': 0.06717763358936645, 'acc': 0.975, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0672 - acc: 0.9750 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9745 - get_regularization_loss: 0.0000e+00{'loss': 0.06916912103712142, 'acc': 0.97445, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0692 - acc: 0.9744 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9744 - get_regularization_loss: 0.0000e+00{'loss': 0.06884465519568572, 'acc': 0.97436666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0688 - acc: 0.9744 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9750 - get_regularization_loss: 0.0000e+00{'loss': 0.06763746102962953, 'acc': 0.97498333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0676 - acc: 0.9750 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9767 - get_regularization_loss: 0.0000e+00{'loss': 0.06193786976640113, 'acc': 0.9767, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0619 - acc: 0.9767 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9758 - get_regularization_loss: 0.0000e+00{'loss': 0.06481473885871625, 'acc': 0.97585, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0648 - acc: 0.9758 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9770 - get_regularization_loss: 0.0000e+00{'loss': 0.06137983807446435, 'acc': 0.9770333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0614 - acc: 0.9770 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9767 - get_regularization_loss: 0.0000e+00{'loss': 0.06146739772524452, 'acc': 0.9766667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0615 - acc: 0.9767 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9776 - get_regularization_loss: 0.0000e+00{'loss': 0.06053255071317156, 'acc': 0.97758335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0605 - acc: 0.9776 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9779 - get_regularization_loss: 0.0000e+00{'loss': 0.058781306141832225, 'acc': 0.9779, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0588 - acc: 0.9779 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9777 - get_regularization_loss: 0.0000e+00{'loss': 0.06038195263814802, 'acc': 0.97775, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0604 - acc: 0.9778 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9775 - get_regularization_loss: 0.0000e+00{'loss': 0.059998667507252926, 'acc': 0.97745, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0600 - acc: 0.9775 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9793 - get_regularization_loss: 0.0000e+00{'loss': 0.05672944404029986, 'acc': 0.9793, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0567 - acc: 0.9793 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9786 - get_regularization_loss: 0.0000e+00{'loss': 0.0566184308272282, 'acc': 0.97868335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 0.0566 - acc: 0.9787 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9791 - get_regularization_loss: 0.0000e+00{'loss': 0.057373640718735505, 'acc': 0.9791167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0574 - acc: 0.9791 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9798 - get_regularization_loss: 0.0000e+00{'loss': 0.05308728471432308, 'acc': 0.9798, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0531 - acc: 0.9798 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9797 - get_regularization_loss: 0.0000e+00{'loss': 0.05501784577145736, 'acc': 0.97965, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0550 - acc: 0.9797 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9792 - get_regularization_loss: 0.0000e+00{'loss': 0.05596537237949669, 'acc': 0.97915, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0560 - acc: 0.9791 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9807 - get_regularization_loss: 0.0000e+00{'loss': 0.05218670869050548, 'acc': 0.98071665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0522 - acc: 0.9807 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9810 - get_regularization_loss: 0.0000e+00{'loss': 0.05183908779255192, 'acc': 0.981, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0518 - acc: 0.9810 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9805 - get_regularization_loss: 0.0000e+00{'loss': 0.05337776777319377, 'acc': 0.98048335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 127us/sample - loss: 0.0534 - acc: 0.9805 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9818 - get_regularization_loss: 0.0000e+00{'loss': 0.04889786466155177, 'acc': 0.98176664, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0489 - acc: 0.9818 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9822 - get_regularization_loss: 0.0000e+00{'loss': 0.04764521452842358, 'acc': 0.98223335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0476 - acc: 0.9822 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9803 - get_regularization_loss: 0.0000e+00{'loss': 0.052607757865191285, 'acc': 0.9802833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0526 - acc: 0.9803 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9814 - get_regularization_loss: 0.0000e+00{'loss': 0.04999705280416444, 'acc': 0.98145, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 121us/sample - loss: 0.0500 - acc: 0.9815 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9815 - get_regularization_loss: 0.0000e+00{'loss': 0.049610636598214235, 'acc': 0.98151666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0496 - acc: 0.9815 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9814 - get_regularization_loss: 0.0000e+00{'loss': 0.05133926848742412, 'acc': 0.9814, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0513 - acc: 0.9814 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9815 - get_regularization_loss: 0.0000e+00{'loss': 0.04887271395686451, 'acc': 0.98153335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0489 - acc: 0.9815 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9824 - get_regularization_loss: 0.0000e+00{'loss': 0.048780832026287684, 'acc': 0.9824333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0488 - acc: 0.9824 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9838 - get_regularization_loss: 0.0000e+00{'loss': 0.04327803715863629, 'acc': 0.9838167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0433 - acc: 0.9838 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9824 - get_regularization_loss: 0.0000e+00{'loss': 0.048728622457397126, 'acc': 0.9824167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0487 - acc: 0.9824 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9837 - get_regularization_loss: 0.0000e+00{'loss': 0.045045188481764246, 'acc': 0.98368335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 118us/sample - loss: 0.0450 - acc: 0.9837 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9836 - get_regularization_loss: 0.0000e+00{'loss': 0.04476169635921348, 'acc': 0.98363334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0448 - acc: 0.9836 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9840 - get_regularization_loss: 0.0000e+00{'loss': 0.04520253226449179, 'acc': 0.984, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0452 - acc: 0.9840 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9834 - get_regularization_loss: 0.0000e+00{'loss': 0.04493641817006404, 'acc': 0.98331666, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0449 - acc: 0.9833 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9842 - get_regularization_loss: 0.0000e+00{'loss': 0.04379575778495637, 'acc': 0.9842167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0438 - acc: 0.9842 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9843 - get_regularization_loss: 0.0000e+00{'loss': 0.04264345634284182, 'acc': 0.98431665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0426 - acc: 0.9843 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9836 - get_regularization_loss: 0.0000e+00{'loss': 0.04480240437681593, 'acc': 0.98361665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0448 - acc: 0.9836 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9835 - get_regularization_loss: 0.0000e+00{'loss': 0.04482566092770661, 'acc': 0.9835, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0448 - acc: 0.9835 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9849 - get_regularization_loss: 0.0000e+00{'loss': 0.042243770672373164, 'acc': 0.98485, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 120us/sample - loss: 0.0422 - acc: 0.9848 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9848 - get_regularization_loss: 0.0000e+00{'loss': 0.04192962048793561, 'acc': 0.98473334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 119us/sample - loss: 0.0419 - acc: 0.9847 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "59744/60000 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9852 - get_regularization_loss: 0.0000e+00{'loss': 0.040674031115528975, 'acc': 0.9852, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0407 - acc: 0.9852 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9843 - get_regularization_loss: 0.0000e+00{'loss': 0.04291868987950523, 'acc': 0.98433334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0429 - acc: 0.9843 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9852 - get_regularization_loss: 0.0000e+00{'loss': 0.0410992207511464, 'acc': 0.98516667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0411 - acc: 0.9852 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9855 - get_regularization_loss: 0.0000e+00{'loss': 0.03879407269872742, 'acc': 0.9855, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.0388 - acc: 0.9855 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9860 - get_regularization_loss: 0.0000e+00{'loss': 0.038870111764142345, 'acc': 0.98605, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0389 - acc: 0.9861 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9844 - get_regularization_loss: 0.0000e+00{'loss': 0.042689246808806154, 'acc': 0.9844, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0427 - acc: 0.9844 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9871 - get_regularization_loss: 0.0000e+00{'loss': 0.03651946026684746, 'acc': 0.98715, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 126us/sample - loss: 0.0365 - acc: 0.9872 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "59552/60000 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9851 - get_regularization_loss: 0.0000e+00{'loss': 0.04120708173626626, 'acc': 0.9851, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 125us/sample - loss: 0.0412 - acc: 0.9851 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "59680/60000 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9855 - get_regularization_loss: 0.0000e+00{'loss': 0.040393061307727234, 'acc': 0.98548335, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0404 - acc: 0.9855 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9860 - get_regularization_loss: 0.0000e+00{'loss': 0.0376220768630182, 'acc': 0.9859667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0376 - acc: 0.9860 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9866 - get_regularization_loss: 0.0000e+00{'loss': 0.038791259812083326, 'acc': 0.9866167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0388 - acc: 0.9866 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9864 - get_regularization_loss: 0.0000e+00{'loss': 0.03761809806622848, 'acc': 0.9864, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0376 - acc: 0.9864 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9865 - get_regularization_loss: 0.0000e+00{'loss': 0.038462764744067346, 'acc': 0.98646665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0385 - acc: 0.9865 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9857 - get_regularization_loss: 0.0000e+00{'loss': 0.03894635592371506, 'acc': 0.98575, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0389 - acc: 0.9858 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "59552/60000 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9869 - get_regularization_loss: 0.0000e+00{'loss': 0.03643566183375745, 'acc': 0.98688334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 123us/sample - loss: 0.0364 - acc: 0.9869 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9867 - get_regularization_loss: 0.0000e+00{'loss': 0.03745078941299192, 'acc': 0.9866833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 124us/sample - loss: 0.0375 - acc: 0.9867 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9870 - get_regularization_loss: 0.0000e+00{'loss': 0.036896527711419186, 'acc': 0.98695, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 122us/sample - loss: 0.0369 - acc: 0.9869 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9868 - get_regularization_loss: 0.0000e+00{'loss': 0.03667303080846638, 'acc': 0.9867667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 7s 125us/sample - loss: 0.0367 - acc: 0.9868 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9883 - get_regularization_loss: 0.0000e+00{'loss': 0.03274931449168477, 'acc': 0.98833334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0327 - acc: 0.9883 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9867 - get_regularization_loss: 0.0000e+00{'loss': 0.0401152204596811, 'acc': 0.98663336, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0401 - acc: 0.9866 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "59616/60000 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9881 - get_regularization_loss: 0.0000e+00{'loss': 0.032903485970450855, 'acc': 0.9881167, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0329 - acc: 0.9881 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9869 - get_regularization_loss: 0.0000e+00{'loss': 0.0390313867631184, 'acc': 0.98686665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 134us/sample - loss: 0.0390 - acc: 0.9869 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9882 - get_regularization_loss: 0.0000e+00{'loss': 0.03328056169170043, 'acc': 0.98821664, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0333 - acc: 0.9882 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "59872/60000 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9883 - get_regularization_loss: 0.0000e+00{'loss': 0.03270205083516412, 'acc': 0.98835, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0327 - acc: 0.9883 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9869 - get_regularization_loss: 0.0000e+00{'loss': 0.0389055869703274, 'acc': 0.98686665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 139us/sample - loss: 0.0389 - acc: 0.9869 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9892 - get_regularization_loss: 0.0000e+00{'loss': 0.03230155085082527, 'acc': 0.98913336, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 140us/sample - loss: 0.0323 - acc: 0.9891 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9880 - get_regularization_loss: 0.0000e+00{'loss': 0.033383449182751795, 'acc': 0.988, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0334 - acc: 0.9880 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "59776/60000 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9879 - get_regularization_loss: 0.0000e+00{'loss': 0.03352666411610565, 'acc': 0.98785, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0335 - acc: 0.9879 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9892 - get_regularization_loss: 0.0000e+00{'loss': 0.030685630218449386, 'acc': 0.9891667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0307 - acc: 0.9892 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9876 - get_regularization_loss: 0.0000e+00{'loss': 0.034944883686192585, 'acc': 0.98758334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 138us/sample - loss: 0.0349 - acc: 0.9876 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9894 - get_regularization_loss: 0.0000e+00{'loss': 0.02908212224190708, 'acc': 0.98938334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0291 - acc: 0.9894 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9870 - get_regularization_loss: 0.0000e+00{'loss': 0.03720978127686843, 'acc': 0.9870333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 136us/sample - loss: 0.0372 - acc: 0.9870 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "59712/60000 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9879 - get_regularization_loss: 0.0000e+00{'loss': 0.03503808366104453, 'acc': 0.98791665, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 131us/sample - loss: 0.0350 - acc: 0.9879 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9885 - get_regularization_loss: 0.0000e+00{'loss': 0.03329641776154558, 'acc': 0.9884833, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0333 - acc: 0.9885 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9888 - get_regularization_loss: 0.0000e+00{'loss': 0.03269436430093112, 'acc': 0.9888333, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 132us/sample - loss: 0.0327 - acc: 0.9888 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9891 - get_regularization_loss: 0.0000e+00{'loss': 0.03047604474339608, 'acc': 0.98911667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0305 - acc: 0.9891 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "59648/60000 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9889 - get_regularization_loss: 0.0000e+00{'loss': 0.03143931937343647, 'acc': 0.9887667, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 130us/sample - loss: 0.0314 - acc: 0.9888 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "59584/60000 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9895 - get_regularization_loss: 0.0000e+00{'loss': 0.030372346376697754, 'acc': 0.98945, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 135us/sample - loss: 0.0304 - acc: 0.9894 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "59808/60000 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9883 - get_regularization_loss: 0.0000e+00{'loss': 0.03506533082872416, 'acc': 0.98828334, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0351 - acc: 0.9883 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9886 - get_regularization_loss: 0.0000e+00{'loss': 0.03335208435633443, 'acc': 0.9886, 'get_regularization_loss': 0.0}\n",
            "60000/60000 [==============================] - 8s 133us/sample - loss: 0.0334 - acc: 0.9886 - get_regularization_loss: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "59840/60000 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9909 - get_regularization_loss: 0.0000e+00{'loss': 0.02609669801287367, 'acc': 0.99085, 'get_regularization_loss': 0.0}\n",
            "\n",
            "Reached 60% accuracy so cancelling training!\n",
            "60000/60000 [==============================] - 9s 142us/sample - loss: 0.0261 - acc: 0.9908 - get_regularization_loss: 0.0000e+00\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f250a54b048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iwgO8W6Plk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}